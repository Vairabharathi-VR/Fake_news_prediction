{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15a54816-b953-4b14-9b3b-e65fa6c1431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8ee7ac-c490-492b-a9d6-7eef2843a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv('E:/Projects/Fake_news/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "091404af-de0e-4612-9804-42e0859f0fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2a24db-5618-437f-bc81-1c18f032108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7f45f2-537b-48fe-bf28-01b5da2cd8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42d300f-e381-4644-8287-09323af0764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data is so large and also its a textual data, so we can replace the null values with empty string\n",
    "data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd495277-3e99-4e56-b930-898eec9e9638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10413\n",
       "0    10387\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts() # Around half the data is fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ff5948-ec4a-44b9-b515-88f89f57936f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c8c501-4017-414e-b98f-431ad993b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using only the title and author column to conduct the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571615aa-93b6-4030-ba83-64a978d2be16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['author'] + ' ' + data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a95a5462-2871-48c8-8eba-62b3257adff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "def stemming(content):\n",
    "    stem = PorterStemmer()\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca8cce1-0221-4245-a399-e9f08e687b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a3d1c2-9378-4e2e-80ce-ad3601d7512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the data and label\n",
    "X = data['content'].values\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145febd2-fc43-4fa8-9a37-833d81e8155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "vec.fit(X)\n",
    "X = vec.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d9841-6daa-4591-b50f-765314a365e5",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4f3c514-42fb-4d2f-b474-b5a98de8b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy of the Logistic regression model is 0.9869591346153846\n",
      "The Testing accuracy of the Logistic regression model is 0.9831730769230769\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=14)\n",
    "log = LogisticRegression()\n",
    "log_model = log.fit(X_train, y_train)\n",
    "log_pred_train = log_model.predict(X_train)\n",
    "log_pred_test = log_model.predict(X_test)\n",
    "print(f'The Training accuracy of the Logistic regression model is {accuracy_score(log_pred_train, y_train)}')\n",
    "print(f'The Testing accuracy of the Logistic regression model is {accuracy_score(log_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c84eb-b1e5-4efb-8f8b-762de9aa5bfd",
   "metadata": {},
   "source": [
    "# Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b49d9a61-f21d-4ab2-8378-d9ed3049dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy of the Decision tree model is 0.9357572115384616\n",
      "The Testing accuracy of the Decision tree model is 0.9454326923076923\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=350)\n",
    "dtree = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "dtree_model = dtree.fit(X_train1, y_train1)\n",
    "dtree_pred_train = dtree_model.predict(X_train1)\n",
    "dtree_pred_test = dtree_model.predict(X_test1)\n",
    "print(f'The Training accuracy of the Decision tree model is {accuracy_score(dtree_pred_train, y_train1)}')\n",
    "print(f'The Testing accuracy of the Decision tree model is {accuracy_score(dtree_pred_test, y_test1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da91bb-056a-4117-ada3-19ca0a03c9e8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9568e393-5d86-4661-82e8-e9bb3988d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training accuracy of the Random forest model is 0.9957932692307693\n",
      "The Testing accuracy of the Random forest model is 0.9908653846153846\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
    "rf = RandomForestClassifier(n_estimators=50,class_weight=None, max_depth=None, min_samples_leaf=2, min_samples_split=10)\n",
    "rf_model = rf.fit(X_train2, y_train2)\n",
    "rf_pred_train = rf_model.predict(X_train2)\n",
    "rf_pred_test = rf_model.predict(X_test2)\n",
    "print(f'The Training accuracy of the Random forest model is {accuracy_score(rf_pred_train, y_train2)}')\n",
    "print(f'The Testing accuracy of the Random forest model is {accuracy_score(rf_pred_test, y_test2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f7738e4-76f6-418a-be0e-07a2c8b00a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vairabharathi VR\\AppData\\Local\\Temp\\ipykernel_11952\\2890132299.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "C:\\Users\\Vairabharathi VR\\AppData\\Local\\Temp\\ipykernel_11952\\2890132299.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n",
      "C:\\Users\\Vairabharathi VR\\AppData\\Local\\Temp\\ipykernel_11952\\2890132299.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Algorithm_name', 'Training_accuracy', 'Testing_accuracy', 'Precision_score', 'F1-score'])\n",
    "results = results.append({\n",
    "    'Algorithm_name' : 'Logistic_Regression',\n",
    "    'Training_accuracy' : accuracy_score(y_train, log_pred_train),\n",
    "    'Testing_accuracy' : accuracy_score(y_test, log_pred_test),\n",
    "    'Precision_score' : precision_score(y_test, log_pred_test),\n",
    "    'F1-score': f1_score(y_test, log_pred_test)}, ignore_index=True)\n",
    "\n",
    "results = results.append({\n",
    "    'Algorithm_name' : 'Decision_Tree',\n",
    "    'Training_accuracy' : accuracy_score(y_train1, dtree_pred_train),\n",
    "    'Testing_accuracy' : accuracy_score(y_test1, dtree_pred_test),\n",
    "    'Precision_score' : precision_score(y_test1, dtree_pred_test),\n",
    "    'F1-score': f1_score(y_test1, dtree_pred_test)}, ignore_index=True)\n",
    "\n",
    "results = results.append({\n",
    "    'Algorithm_name' : 'Random_Forest',\n",
    "    'Training_accuracy' : accuracy_score(y_train2, rf_pred_train),\n",
    "    'Testing_accuracy' : accuracy_score(y_test2, rf_pred_test),\n",
    "    'Precision_score' : precision_score(y_test2, rf_pred_test),\n",
    "    'F1-score': f1_score(y_test2, rf_pred_test)}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4b47782-cfc9-4cc3-a27c-c8b7b94088e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm_name</th>\n",
       "      <th>Training_accuracy</th>\n",
       "      <th>Testing_accuracy</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>0.983173</td>\n",
       "      <td>0.975152</td>\n",
       "      <td>0.983452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>0.935757</td>\n",
       "      <td>0.945433</td>\n",
       "      <td>0.909483</td>\n",
       "      <td>0.948954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.995793</td>\n",
       "      <td>0.990865</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.990803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Algorithm_name  Training_accuracy  Testing_accuracy  Precision_score  \\\n",
       "0  Logistic_Regression           0.986959          0.983173         0.975152   \n",
       "1        Decision_Tree           0.935757          0.945433         0.909483   \n",
       "2        Random_Forest           0.995793          0.990865         0.988889   \n",
       "\n",
       "   F1-score  \n",
       "0  0.983452  \n",
       "1  0.948954  \n",
       "2  0.990803  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdeb10e-fc71-4433-b7b5-554b3493be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering all the above metrics, all of our model is performing well. The choice depend on our \n",
    "# specific requirements. Here I am considering based on the Testing accuracy, precision_score and \n",
    "# F1-score with that I choose Random Forest as my Ideal model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
